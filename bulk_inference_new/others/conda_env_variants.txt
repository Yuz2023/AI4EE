# ============================================
# environment-cpu.yml - CPU-only installation
# ============================================
name: llama-inference-cpu
channels:
  - pytorch
  - conda-forge
  - defaults

dependencies:
  - python=3.10
  - pytorch-cpu>=2.5.0
  - cpuonly  # CPU-only PyTorch
  - numpy>=1.26
  - pandas>=1.3
  - scipy>=1.14
  - scikit-learn>=0.23
  - pip
  
  - pip:
      - transformers>=4.46.0
      - accelerate>=0.25.0
      - fastapi>=0.115.0
      - uvicorn[standard]>=0.32.0
      - promptbench>=0.0.4
      - datasets>=2.19.0
      - tqdm>=4.66.0
      - requests>=2.32.0

# ============================================
# environment-minimal.yml - Minimal setup
# ============================================
name: llama-inference-minimal
channels:
  - pytorch
  - nvidia
  - conda-forge
  - defaults

dependencies:
  - python=3.10
  - pytorch>=2.5.0
  - pytorch-cuda=12.1
  - numpy
  - pip
  
  - pip:
      - vllm>=0.6.4
      - transformers>=4.46.0
      - fastapi>=0.115.0
      - uvicorn>=0.32.0
      - promptbench>=0.0.4
      - tqdm

# ============================================
# environment-dev.yml - Development setup
# ============================================
name: llama-inference-dev
channels:
  - pytorch
  - nvidia
  - conda-forge
  - defaults

dependencies:
  - python=3.10
  - pytorch>=2.5.0
  - pytorch-cuda=12.1
  - numpy>=1.26
  - pandas>=1.3
  - matplotlib>=3.8
  - jupyterlab
  - ipython
  - pip
  
  - pip:
      - vllm>=0.6.4
      - transformers>=4.46.0
      - fastapi>=0.115.0
      - uvicorn[standard]>=0.32.0
      - promptbench>=0.0.4
      - datasets>=2.19.0
      # Development tools
      - pytest>=7.0.0
      - pytest-asyncio
      - pytest-cov
      - black>=22.0.0
      - flake8>=4.0.0
      - mypy
      - isort
      - pre-commit
      # Debugging tools
      - ipdb
      - rich
      - loguru
      # Documentation
      - sphinx
      - sphinx-rtd-theme

# ============================================
# environment-docker.yml - For Docker containers
# ============================================
name: llama-inference-docker
channels:
  - pytorch
  - nvidia
  - conda-forge
  - defaults

dependencies:
  - python=3.10
  - pytorch>=2.5.0
  - pytorch-cuda=12.1
  - pip
  
  - pip:
      - vllm>=0.6.4
      - transformers>=4.46.0
      - fastapi>=0.115.0
      - uvicorn>=0.32.0
      - promptbench>=0.0.4
      - datasets>=2.19.0
      - numpy>=1.26
      - pandas>=1.3
      - tqdm>=4.66
      - psutil>=5.9

variables:
  PYTORCH_CUDA_ALLOC_CONF: max_split_size_mb:512
  CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7